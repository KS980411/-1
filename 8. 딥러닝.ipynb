{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d1bd92",
   "metadata": {},
   "source": [
    "# 8. 딥러닝\n",
    "\n",
    "딥러닝은 층을 깊게 한 심층 신경망이다. 심층 신경망은 지금까지 설명한 신경망을 바탕으로 뒷단에 층을 추가하기만 하면 만들 수 있지만, 커다란 문제가 몇 개 있다\n",
    "\n",
    "이번 장에서는 딥러닝의 특징과 과제, 그리고 가능성을 살펴본다. 또, 오늘날의 첨단 딥러닝에 대한 설명도 준비했다.\n",
    "\n",
    "## 더 깊게\n",
    "\n",
    "신경망에 대해서 많은 것을 배웠다.\n",
    "\n",
    "신경망을 구성하는 다양한 계층과 학습에 효과적인 기술, 영상 분야에 특히 유효한 CNN과 매개변수 최적화 기법 등이 떠오를 것이다. 이 모두가 딥러닝에서 중요한 기술이다.\n",
    "\n",
    "이번 절에서는 그동안 배운 기술을 집약하고 심층 신경망을 만들어 MNIST 데이터셋의 손글씨 숫자 인식에 도전하려 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e18b2",
   "metadata": {},
   "source": [
    "### 더 깊은 신경망으로\n",
    "\n",
    "이번 절에서는 [그림 8-1]과 같이 구성된 CNN을 만들고자 한다.\n",
    "\n",
    "<font color = blue> [263페이지 그림 8-1 참고] </font>\n",
    "\n",
    "지금까지 구현한 신경망보다 층이 깊은 것을 확인할 수 있다. 여기에서 사용하는 합성곱 계층은 모두 3 x 3 크기의 작은 필터로, 층이 깊어지면서 채널 수가 더 늘어나는 것이 특징이다. 합성곱 계층의 채널 수는 앞 계층으로부터 순서대로 16, 16, 32, 32, 64, 64로 늘어난다.\n",
    "\n",
    "그림과 같이 풀링 꼐층을 추가해서 중간 데이터의 공간 크기를 저맟 줄여간다. 그리고 마지막 단의 완전연결 계층에서는 드롭아웃 계층을 사용한다.\n",
    "\n",
    "가중치 초깃값으로 He 초깃값을 사용하고, 가중치 매개변수 갱신에는 Adam을 이용한다. 이상을 정리하면 이 신경망의 특징은 다음과 같다.\n",
    "\n",
    "- 3x3의 작은 필터를 사용한 합성곱 계층\n",
    "- 활성화 함수는 ReLU\n",
    "- 완전연결 계층 뒤에 드롭아웃 계층 사용\n",
    "- Adam을 사용해 최적화\n",
    "- 가중치 초깃값은 'He의 초깃값'\n",
    "\n",
    "결과적으로 이 신경망의 정확도는 $99.38%$이다. 이 정도면 매우 훌륭한 성능이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215d659",
   "metadata": {},
   "source": [
    "### 정확도를 더 높이려면\n",
    "\n",
    "<What is the class of this image?> 사이트에서는 다양한 데이터셋을 대상으로 그동안 논문 등에서 발표한 기법들의 정확도 순위를 정리해두었다.\n",
    "\n",
    "순위를 보면 'Neural Networks'나, 'Deep', 'Convolutional' 이라는 키워드가 돋보인다. 상위권은 대부분 CNN을 기초로 하는 기법들이 많다.\n",
    "\n",
    "다만 이 목록의 기법들이 사용하는 CNN들은 그다지 깊지 않다(합성곱 계층 2개에 완전연결 계층 2개인 신경망).\n",
    "\n",
    "이 목록의 상위 기법을 참고하면 정확도를 더 높일 수 있는 기술이나 힌트를 확인할 수 있다. 예를 들어 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌하고 있다. 특히 데이터 확장은 손쉬운 방법이면서도 정확도 개선에 아주 효과적이다.\n",
    "\n",
    "**데이터 확장**은 입력 이미지(훈련 이미지)를 알고리즘을 동원해 인위적으로 확장한다. [그림 8-4]와 같이 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 **이미지의 개수를 늘리는 것** 이다. 이는 **데이터가 몇 개 없을 때 특히 효과적인 수단** 이다.\n",
    "\n",
    "데이터 확장은 다양한 방법으로 이미지를 확장할 수 있다.\n",
    "\n",
    "예를 들어 **이미지 일부를 잘라내는 crop**이나, **좌우를 뒤집는 flip** 등이 있다. 일반적인 이미지에는 밝기 등의 외형 변화나 확대/축소 등의 스케일 변화도 효과적이다. 어쨌든 데이터 확장을 동원해 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝의 인식 수준을 개선할 수 있다.\n",
    "\n",
    "쉬운 트릭이라 가볍게 생각할지도 모르지만, 좋은 결과를 가져오는 경우가 많다. 이 책에서 데이터 확장은 구현하지 않지만, 어렵지 않은 방식이니 흥미가 있는 사람은 한 번 도전해봐도 좋을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba4b3d",
   "metadata": {},
   "source": [
    "### 깊게 하는 이유\n",
    "\n",
    "'층을 깊게 하는 것'이 왜 중요한가에 대한 이론적인 근거는 많이 부족한 것이 사실이다.\n",
    "\n",
    "그래도 지금까지의 연구와 실험 결과를 바탕으로 설명할 수 있는 것은 몇 가지 있다. 이번 절에서는 **'층을 깊게 하는 것'의 중요성**에 대해서, 이를 뒷받침하는 데이터와 설명을 몇 가지 소개하겠다.\n",
    "\n",
    "우선 층을 깊게 하는 것의 중요성은 ILSVRC로 대표되는 대규모 이미지 인식 대회의 결과에서 파악할 수 있다. 이 대회에서 최근 상위를 차지한 기법 대부분은 딥러닝 기반이며, 그 경향은 신경망을 더 깊게 만드는 방향으로 가고 있다. 층의 깊이에 비례해 정확도가 좋아지는 것이다.\n",
    "\n",
    "층을 깊게 할 때의 이점을 설명하면, 첫 번째는 **신경망의 매개변수 수가 줄어든다는 것**이다. 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은(혹은 그 이상) 수준의 표현력을 달성할 수 있다. 합성곱 연산에서의 필터 크기에 주목해 생각해보면 쉽게 이해될 것이다. 예를 한 번 보자.\n",
    "\n",
    "[그림 8-5]는 5 x 5 필터로 구성된 합성곱 계층이다.\n",
    "\n",
    "<font color = blue> [267페이지 그림 8-5 참고] </font>\n",
    "\n",
    "여기에서 주목할 점은 출력 데이터의 각 노드가 **입력 데이터의 어느 영역으로부터 계산되었느냐**는 것이다. 당연하지만 [그림 8-5]의 예에서는 각각의 출력 노드는 입력 데이터의 5 x 5 크기 영역에서 계산된다.\n",
    "\n",
    "이어서 [그림 8-6]을 보자.\n",
    "\n",
    "<font color = blue> [268페이지 그림 8-6 참고] </font>\n",
    "\n",
    "이 경우 출력 노드 하나는 중간 데이터의 3 x 3 영역에서 계산된다. 그럼 중간 데이터의 3 x 3 영역은 그 전 입력 데이터의 어느 영역에서 계산될까? 5 x 5 크기의 영역에서 계산되어 나오는 것을 알 수 있다.\n",
    "\n",
    "즉, [그림 8-6]의 출력 데이터는 입력 데이터의 5 x 5 영역을 보고 계산하게 된다.\n",
    "\n",
    "5 x 5 합성곱 연산 1회는 3 x 3의 합성곱 연산을 2회 수행하여 대체할 수 있다. 게다가 **전자의 매개변수가 25개(5 x 5)인 반면, 후자는 총 18개 (2 x 3 x 3)** 이며, 매개변수 수는 층을 반복할수록 적어진다. 그리고 그 개수의 차이는 **층이 깊어질수록 커진다**.\n",
    "\n",
    "예를 들어 3 x 3 합성곱 연산을 3회 반복하면 매개변수는 모두 27개가 되지만, 같은 크기의 영역을 1회의 합서곱 연산으로 보기 위해서는 7 x 7 크기의 필터, **즉, 매개변수 49개가 필요**하다.\n",
    "\n",
    "<font color = blue> *NOTE. 작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은 수용 영역을 소화할 수 있다는 데 있다. (수용 영역은 뉴런에 변화를 일으키는 국소적인 공간 영역이다) 게다가 층을 거듭하면서 활성화 함수를 합성곱 계층 사이에 끼움으로써 신경망의 표현력이 개선된다. 이는 활성화 함수가 신경망에 비선형 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 떄문이다. </font>\n",
    "\n",
    "학습의 효율성도 층을 깊게 하는 것의 이점이다. 층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다.\n",
    "\n",
    "CNN의 합성곱 계층이 **정보를 계층적으로 추출하고 있음**을 설명했다. 앞단의 합성곱 계층에서는 에지 등의 **단순한 패턴에 뉴런이 반응**하고 층이 깊어지면서 텍스처와 사물의 일부와 같이 점차 더 복잡한 것에 반응한다고 설명하였다.\n",
    "\n",
    "그런 네트워크 계층 구조를 기억해두고, '개'를 인식하는 문제를 생각해보자.\n",
    "\n",
    "이 문제를 얕은 신경망에서 해결하려면 **합성곱 계층은 개의 특징 대부분을 한 번에 이해**해야 한다. 견종도 다양하고, 어느 각도에서 찍은 사진이냐 따라 완전히 다르게 보일 수도 있다. 그래서 개의 특징을 이해하려면 변화가 풍부하고 많은 학습 데이터가 필요하고, 결과적으로 학습 시간이 오래 걸린다.\n",
    "\n",
    "그러나 신경망을 깊게 하면 **학습해야 할 문제를 계층적으로 분해**할 수 있다. 각 층이 학습해야 할 문제를 더 단순한 문제로 대체할 수 있는 것이다. 예를 들어 처음 층은 에지 학습에 전념하여 적은 학습 데이터로 효율적으로 학습할 수 있다. 개가 등장하는 이미지보다 에지를 포함한 이미지는 많고, 에지의 패턴은 개라는 패턴보다 구조가 훨씬 간단하기 떄문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cb7cb",
   "metadata": {},
   "source": [
    "## 딥러닝의 초기 역사\n",
    "\n",
    "ILSVRC에서 딥러닝에 기초한 AlexNet이 압도적인 성적으로 우승하자, 그동안의 이미지 인식에 대한 접근법을 뿌리부터 뒤흔들었다.\n",
    "\n",
    "이번 절에서는 ILSVRC 대회를 축으로 최근의 딥러닝 트렌드를 살펴보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd46c02",
   "metadata": {},
   "source": [
    "### 이미지넷\n",
    "\n",
    "이미지넷은 100만 장이 넘는 이미지를 담고 있는 데이터셋이다. 다양한 종류의 이미지를 포함하며, 각 이미지에는 레이블(클래스 이름)이 붙어 있습니다.\n",
    "\n",
    "매년 열리는 ILSVRC는 이 거대한 데이터셋을 사용하여 이미지 인식 기술의 탑을 겨루는 대회이다.\n",
    "\n",
    "ILSVRC 대회에는 시험 항목이 몇 가지 있는데, 그 중 하나가 **분류**이다. 분류 부문에서는 1,000개의 클래스를 제대로 분류하는지를 겨룬다.\n",
    "\n",
    "그렇다면 2010년부터 최근까지 ILSVRC의 분류 부분 우승팀의 톱-5 오류를 살펴보자. **톱-5 오류**란 확률이 가장 높다고 생각하는 후보 클래스 5개 안에 정답이 포함되지 않은, 즉 5개 모두가 틀린 비율이다.\n",
    "\n",
    "<font color = blue> [270페이지 그림 8-8 참고] </font>\n",
    "\n",
    "여기에서 주목할 점은 2012년 이후 선두는 항상 딥러닝 방식이라는 것이다. 실제로 2012년의 AlexNet이 오류율을 크게 낮췄고, 그 후 딥러닝을 활용한 기법이 꾸준히 정확도를 개선해왔다. 특히 2015년에는 150층이 넘는 심층 신경망인 ResNet이 오류율을 $3.5%$까지 낮췄다. 이 결과는 일반적인 인간의 인식 능력을 넘어섰다고 한다.\n",
    "\n",
    "최근 몇 년 빼어난 성적을 거두고 있는 딥러닝 중에서도 VGG, GoogLeNet, ResNet은 특히 유명하며, 다양한 딥러닝 분야에서 활용된다.\n",
    "\n",
    "이어지는 절들에서는 이 세 가지 유명 신경망을 간단히 소개하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8385a73",
   "metadata": {},
   "source": [
    "### VGG\n",
    "\n",
    "VGG는 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN이다. 다만, 비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층(혹은 19층)으로 심화한 것이 특징이다(층의 깊이에 따라서 'VGG16'과 'VGG19'로 구분하기도 한다).\n",
    "\n",
    "<font color = blue> [271페이지 그림 8-9 참고] </font>\n",
    "\n",
    "VGG에서 주목할 점은 **3 x 3의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다**는 것이다. 그림에서 보듯 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복한다. 그리고 마지막에는 완전연결 계층을 통과시켜 결과를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a8256",
   "metadata": {},
   "source": [
    "### GoogLeNet\n",
    "\n",
    "GoogLeNet의 구성은 [그림 8-10]과 같다. 그림의 사각형이 합성곱 계층과 풀링 계층 등의 계층을 나타낸다.\n",
    "\n",
    "<font color = blue> [272페이지 그림 8-10 참고] </font>\n",
    "\n",
    "기본적으로는 지금까지 보아온 CNN과 다르지 않다. 단, GoogLeNet은 세로 방향 깊이뿐 아니라 **가로 방향도 깊다는 점이 특징**이다.\n",
    "\n",
    "GoogLeNet에는 가로 방향에 '폭'이 있다. 이를 인셉션 구조라 하며, 그 기반 구조는 [그림 8-11]과 같다.\n",
    "\n",
    "<font color = blue> [272페이지 그림 8-11 참고] </font>\n",
    "\n",
    "인셉션 구조는 크기가 다른 필터와 풀링을 여러 개 적용하여 그 결과를 결합한다. 이 인셉션 구조를 하나의 빌딩 블록(구성 요소)으로 사용하는 것이 GoogLeNet의 특징이다.\n",
    "\n",
    "또 GoogLeNet에서는 1 x 1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용한다. 이 1 x 1의 합성곱 연산은 채널 쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여한다.\n",
    "\n",
    "<font color = purple> GoogLeNet에 대한 대략적인 설명은 https://ardino.tistory.com/44 참고 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcbf3e",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "**ResNet**은 지금까지보다 층을 더 깊게 할 수 있는 특별한 장치가 있다는 특징이 있다.\n",
    "\n",
    "층을 깊게 하는 것은 성능 향상에 중요하다. 하지만 딥러닝 학습에서는 층이 지나치게 깊으면 학습이 잘 되지 않고, 오히려 성능이 떨어지는 경우도 많다. ResNet에서는 그런 문제를 해결하기 위해서 **스킵 연결**을 도입한다.\n",
    "\n",
    "이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심이다.\n",
    "\n",
    "스킵 연결이란, **입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조**를 말한다.\n",
    "\n",
    "<font color = blue> [273페이지 그림 8-12 참고] </font>\n",
    "\n",
    "[그림 8-12]에서는 입력 $x$를 연속한 두 합성곱 계층을 건너뛰어 출력에 바로 연결한다.\n",
    "\n",
    "이 단축 경로가 없었다면 두 합성곱 계층의 출력이 $F(x)$가 되나, 스킵 연결로 인해 $F(x) + x$가 되는 것이 핵심이다.\n",
    "\n",
    "스킵 연결은 층이 깊어져도 학습을 효율적으로 할 수 있도록 해주는데, 이는 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문이다.\n",
    "\n",
    "<font color = blue> *NOTE. 스킵 연결은 입력 데이터를 그대로 흘리는 것으로, 역전파 때도 상류의 기울기를 그대로 하류로 보낸다. 여기서의 핵심은  **상류의 기울기에 아무런 수정도 가하지 않고 그대로 흘린다는 것**이다. 그래서 스킵 연결로 기울기가 작아지거나 지나치게 커질 걱정 없이 앞 층에 의미 있는 기울기가 전해지리라 기대할 수 있다. 층을 깊게 할수록 기울기가 작아지는 소실 문제를 이 스킵 연결이 줄여준다.* </font>\n",
    "\n",
    "<font color = purple> ResNet의 $F(x) + x$은 엄밀히 말하자면 입력값과 출력값의 차원이 동일할 때 성립하지만, 입력값과 출력값의 차원이 동일하지 않는 경우도 $x$에 후처리를 해주면서 계산이 성립할 수 있다. </font>\n",
    "\n",
    "ResNet은 VGG 신경망을 기반으로 스킵 연결을 도입하여 층을 깊게 했다. 그 결과는 [그림 8-13]과 같다.\n",
    "\n",
    "<font color = blue> [274페이지 그림 8-13 참고] </font>\n",
    "\n",
    "[그림 8-13]과 같이 ResNet은 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 한다. 실험 결과 150층 이상으로 해도 정확도가 오르는 모습을 확인할 수 있다.\n",
    "\n",
    "<font color = blue> *NOTE. 이미지넷이 제공하는 데이터셋으로 학습한 가중치 값들은 실제 제품에 활용해도 효과적이고, 그렇게 많이 이용하고 있다. 이를 **전이 학습**이라고 해서, 학습된 가중치 일부를 다른 신경망에 복사한 다음, 그 상태로 재학습을 수행한다. 예를 들어 VGG와 구성이 같은 신경망을 준비하고, 미리 학습된 가중치를 초깃값으로 설정한 후, 새로운 데이터셋을 대상으로 재학습을 수행한다. 전이 학습은 보유한 데이터셋이 적을 때 특히 유용하다.* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20caf50",
   "metadata": {},
   "source": [
    "## 더 빠르게\n",
    "\n",
    "딥러닝에서는 대량의 연산을 수행해야 하나, CPU 만으로는 딥러닝을 처리하기는 부족한 것이 현실이다.\n",
    "\n",
    "따라서 딥러닝 프레임워크 대부분은 **GPU**를 활용해 대량의 연산을 고속으로 처리할 수 있다. \n",
    "\n",
    "최근 프레임워크에서는 학습을 복수의 GPU와 여러 기기로 분산 수행하기 시작했다. 이번 절에서는 딥러닝의 고속화에 대해서 이야기할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba9745",
   "metadata": {},
   "source": [
    "### 사물 검출\n",
    "\n",
    "사물 검출은 이미지 속에 담긴 사물의 위치와 종류(클래스)를 알아내는 기술이다.\n",
    "\n",
    "사물 검출은 사물 인식보다 어려운 문제이다. 사물 인식은 이미지 전체를 대상으로 했는데, 사물 검출에서는 이미지 어딘가에 있을 사물의 위치까지 알아내야 한다. 게다가 한 이미지에 여러 사물이 존재할 수 있다.\n",
    "\n",
    "이런 사물 검출 문제에 CNN을 기반으로 한 기법이 몇 가지 제안되었다. 이 기법들이 발군의 성능을 보여 사물 검출에도 딥러닝이 효과적임을 시사하고 있다.\n",
    "\n",
    "CNN을 이용해서 사물 검출을 수행하는 방식은 몇 가지가 있는데, 그중에서도 **R-CNN**이 유명하다. R-CNN의 처리 흐름은 다음과 같다.\n",
    "\n",
    "- 1. 입력 이미지 입력\n",
    "- 2. 후보 영역 추출\n",
    "- 3. CNN 특징 계산\n",
    "- 4. 영역 분류\n",
    "\n",
    "여기에서 주목할 부분은 '후보 영역 추출'과 'CNN 특징 계산'이다. 먼저 사물이 위치한 영역을 찾아내고, 추출한 각 영역에 CNN을 적용하여 클래스를 분류하는 것이다. 이미지를 사각형으로 변형하거나 분류할 때 서포트 벡터 머신을 사용하는 등 실제 처리 흐름은 다소 복잡하지만, 큰 틀에서는 이 두 가지 처리(후보 영역 추출과 CNN 특징 계산)로 구성된다.\n",
    "\n",
    "후보 영역 추출에는 컴퓨터 비전 분야에서 발전해온 다양한 기법을 사용할 수 있고, R-CNN 논문에서는 Selective Search 기법을 사용했다. 최근에는 이 후보 영역 추출까지 CNN으로 처리하는 Faster R-CNN 기법도 등장했따. Faster R-CNN은 모든 일을 하나의 CNN에서 처리하기 때문에 아주 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1e4cf",
   "metadata": {},
   "source": [
    "### 분할\n",
    "\n",
    "**분할**이란 이미지를 픽셀 수준에서 분류하는 문제이다. [그림 8-19]와 같이 픽셀 단위로 객체마다 채색된 지도(supervised) 데이터를 사용해 학습한다. 그리고 추론할 때 입력 이미지의 모든 픽셀을 분류한다.\n",
    "\n",
    "지금까지 구현한 신경망은 분류를 이미지 전체를 대상으로 해왔다. 이를 픽셀 수준에 적용하려면 어떻게 될까?\n",
    "\n",
    "신경망을 이용해 분할하는 가장 단순한 방법은 모든 픽셀 각각을 추론하는 것이다. 예를 들어, 어떤 직사각형 영역의 중심 픽셀의 클래스를 분류하는 신경망을 만들어서, 모든 픽셀을 대상으로 하나씩 추론 작업을 실행한다.\n",
    "\n",
    "이런 식으로는 픽셀의 수만큼 forward 처리를 해야 하며 긴 시간이 걸리게 된다. 합성곱 연산에서 많은 영역을 쓸데없이 다시 계산하는 것이 문제가 되기 때문이다.\n",
    "\n",
    "이러한 낭비를 줄여주는 기법으로 FCN(Fully Convolutional Network)가 고안되었는데, 이는 단 한 번의 forward 처리로 모든 픽셀의 클래스를 분류해주는 놀라운 기법이다.\n",
    "\n",
    "Fully Convolutional Network를 직역하면 '합성곱 계층만으로 구성된 네트워크'가 된다.\n",
    "\n",
    "일반적인 CNN이 완전연결 계층을 이용하는 반면, 이 FCN은 이 완전연결 계층을 '같은 기능을 하는 합성곱 계층'으로 바꾼다. 사물 인식에서 사용한 신경망의 완전연결 계층에서는 중간 데이터의 공간 볼륨(다차원 형태)을 1차원으로 변환하여 한 줄로 늘어선 노드들이 처리했으나, FCN에서는 공간 볼륨을 유지한 채 마지막 출력까지 처리할 수 있다.\n",
    "\n",
    "FCN은 마지막에 공간 크기를 확대하는 처리를 도입했다는 것도 특징이다. 이 확대 처리로 인해 줄어든 중간 데이터를 입력 이미지와 같은 크기까지 단번에 확대할 수 있다. FCN의 마지막에 수행하는 확대는 이중 선형 보간에 의한 선형 확대이다. FCN에서는 이 선형 확대를 역합성곱 연산으로 구현하고 있다.\n",
    "\n",
    "<font color = blue> *NOTE. 완전연결 계층에서는 출력이 모든 입력과 연결된다. 이와 같은 구성을 합성곱 계층으로도 구현할 수 있다. 가령 입력 크기가 32 x 10 x 10(채널 32개, 높이 10, 너비 10)인 데이터에 대한 완전연결 계층은 필터가 32 x 10 x 10인 합성곱 계층으로 대체할 수 있다. 만약, 완전연결 계층의 출력 노드가 100개라면, 합성곱 계층에서는 이 필터를 100개 준비하면 완전히 같은 처리를  할 수 있다. 이처럼 완전연결 계층은 **같은 일을 수행하는 합성곱 계층으로 대체**할 수 있다.* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea1f1a",
   "metadata": {},
   "source": [
    "### 사진 캡션 생성\n",
    "\n",
    "컴퓨터 비전과 자연어를 융합한 연구가 있다. 사진을 주면, 그 사진을 설명하는 글(사진 캡션)을 자동으로 생성하는 연구이다.\n",
    "\n",
    "<font color = blue> [283페이지 그림 8-21 참고] </font>\n",
    "\n",
    "예를 들어 [그림 8-21]의 첫 번째는 사진만 보고 \"비포장도로에서 오토바이를 타는 사람\"이라는 문장을 자동으로 생성했다. 설명과 사진이 정확히 일치한다.\n",
    "\n",
    "딥러닝으로 사진 캡션을 생성하는 방법으로는 NIC 모델이 대표적이다. NIC는 심층 CNN과 자연어를 다루는 **순환 신경망(RNN)** 으로 구성된다. RNN은 순환적 관계를 갖는 신경망으로 **자연어나 시계열 데이터 등의 연속된 데이터를 다룰 때 많이 활용**한다.\n",
    "\n",
    "구조는 283페이지의 그림 8-22 참고\n",
    "\n",
    "NIC는 CNN으로 사진에서 특징을 추출하고, 그 특징을 RNN으로 넘긴다. RNN은 CNN이 추출한 특징을 초깃값으로 하여 텍스트를 순환적으로 생성한다.\n",
    "\n",
    "기본적으로 NIC는 2개의 신경망(CNN과 RNN)을 조합한 간단한 구성이다. 또한, 사진이나 자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 **멀티모달 처리**라고 한다.\n",
    "\n",
    "<font color = blue> *NOTE. RNN의 R은 Recurrent(순환적)을 뜻한다. 여기에서 순환은 신경망의 순환적 네트워크 구조를 말한다. 이 순환적인 구조로 인해 이전에 생성한 정보에 영향을 받는(바꾸어 말하면, 과거의 정보를 기억하는) 점이 RNN의 특징이다. 예를 들어 '나'라는 단어를 생성한 뒤 '잤다'라는 단어를 생성하면 먼저 만든 '나'의 영향을 받아 '는'이라는 조사가 자동으로 생성되어, 최종적으로 '나는 잤다'라는 문장이 완성되는 식이다. 이처럼 자연어와 시계열 데이터 등 연속성 있는 데이터를 다룰 때 RNN은 과거의 정보를 기억하면서 동작한다. </font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2e618",
   "metadata": {},
   "source": [
    "## 딥러닝의 미래\n",
    "\n",
    "### 이미지 스타일 변환\n",
    "\n",
    "딥러닝을 활용해 화가처럼 그림을 그리는 연구가 있다. 두 이미지를 입력해서 새로운 그림을 생성하는 연구이다. 하나는 '콘텐츠 이미지', 다른 하나는 '스타일 이미지'라 부르는데, 이 둘을 조합해 새로운 그림을 그려준다.\n",
    "\n",
    "예를 들어 고흐의 화풍을 콘텐츠 이미지에 적용하도록 지정하면 이를 기초로 딥러닝이 새로운 그림을 그린다. 이 기법을 담은 [A Neural Algorithm of Artistic Style] 논문은 발표되자마자 전 세계에서 많은 이목을 끌었다.\n",
    "\n",
    "여기서는 자세히 설명하지는 않겠지만, 큰 틀만 이야기하자면 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습한다. 이렇게 하면 입력 이미지를 콘텐츠 이미지의 형태를 흉내낼 수 있다. 또, 스타일 이미지의 화풍을 흡수하기 위해 '스타일 행렬'이라는 개념을 도입한다. 그 스타일 행렬의 오차를 줄이도록 학습하여 입력 이미지를 고흐의 화풍과 비슷해지게 만들 수 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69852f51",
   "metadata": {},
   "source": [
    "### 이미지 생성\n",
    "\n",
    "이미지의 스타일을 변화시키려면 이미지 두 장을 입력해야 했다. 한편 아무런 아무런 입력 이미지 없이도 새로운 이미지를 그려내는 연구도 진행 중이다.\n",
    "\n",
    "물론 먼저 대량의 학습 이미지를 사용하여 학습하지만, 학습이 끝난 후에는 아무런 입력 이미지 없이도 새로운 그림을 그려낸다. 가령 딥러닝으로 침실 이미지를 아무 것도 없는 상태에서 생성하는 것도 가능하다. 이를 DCGAN 기법이라 한다.\n",
    "\n",
    "이미지들은 진짜 사진처럼 보일지 모르겠지만, 모두 DCGAN 기법을 사용해 새롭게 생성한 이미지이다. 즉, DCGAN이 그린, 아직 아무도 본 적 없는 이미지(학습 데이터에는 존재하지 않는 이미지)이며, 처음부터 새로 생성한 이미지이다.\n",
    "\n",
    "DCGAN은 이미지를 생성하는 과정을 모델화한다. 그 모델을 대량의 이미지를 사용해 학습하고, 학습이 끝나면 그 모델을 이용하여 새로운 그림을 생성할 수 있다.\n",
    "\n",
    "DCGAN도 딥러닝을 사용한다. DCGAN 기술의 핵심은 생성자와 식별자라고 불리는 2개의 신경망을 이용한다는 것이다. 생성자가 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지(생성자가 생성한 이미지인지, 아니면 실제로 촬영된 이미지인지)를 판정한다. 그렇게 해서 둘을 겨루도록 학습시켜, 생성자는 더 정교한 가짜 이미지 생성 기술을 학습하고 식별자는 더 정확하게 간파할 수 있는 감정사로 성장한다.\n",
    "\n",
    "이렇게 둘의 능력을 부지런히 갈고닦고 한다는 개념이 **GAN** 기술의 재미난 점이다. 그렇게 성장한 생성자는 최종적으로는 진짜와 착각할 정도의 이미지를 그려내는 능력을 기르는 것이다.\n",
    "\n",
    "<font color = blue> *NOTE. 이전까지 살펴본 기계학습 문제는 **지도 학습**이라는 유형의 문제였다. 지도 학습은 손글씨 숫자 인식처럼 이미지 데이터와 정답 레이블을 짝지은 데이터셋을 이용한다. 그러나 이번 절에서 거론한 문제는 지도용 데이터를 주어지지 않고, 단지 대량의 이미지만 주어진다. 즉, 지도 없이 스스로 학습하는 **자율 학습(비지도 학습, unsupervised learning)** 문제이다. 자율 학습은 비교적 오래전부터 연구된 분야지만, 최근에는 그다지 활발하게는 연구되지 않는 느낌이다. 최근 딥러닝을 사용한 DCGAN 등과 같은 기법이 시선을 끌면서, 앞으로 자율 학습도 새로운 도약을 기대할 수 있을지도 모른다.* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d4888",
   "metadata": {},
   "source": [
    "### Deep Q-Network (강화학습)\n",
    "\n",
    "사람이 시행착오를 겪으며 배우듯 컴퓨터도 시행착오 과정에서 스스로 학습하게 하려는 분야가 있다. 이는 '가르침'에 의존하는 지도 학습과는 다른 분야로 **강화학습** 이라고 한다.\n",
    "\n",
    "강화학습에서는 에이전트라는 것이 환경에 맞게 행동을 선택하고, 그 행동에 의해서 환경이 변한다는 것이 기본적인 틀이다.\n",
    "\n",
    "환경이 변화하면 에이전트는 어떠한 보상을 얻고, 더 나은 보상을 받는 쪽으로 에이전트의 행동 지침을 바로잡는 것이 강화학습의 목적이다.\n",
    "\n",
    "여기서 주의점은 보상은 정해진 것이 아니라 '예상 보상'이라는 것이다. 예를 들어 <슈퍼 마리오 브라더스>에서 마리오를 오른쪽으로 이동했을 때 얻는 보상이 항상 명확한 것은 아니다. 어떤 상황에서 이동한 것이냐에 따라 보상은 천차만별이 될 수 있다. 이런 불명확한 상황에서는 게임 점수나 게임 종료 등의 명확한 지표로부터 역산해서 예상 보상을 정해야 한다. 만약 지도 학습이었다면 행동에 대한 지도를 통해 올바른 평가를 받을 수 있었을 것이다.\n",
    "\n",
    "딥러닝을 사용한 강화학습 중 **Deep Q-Network(일명 DQN)** 이라는 방법이 있다. 이는 Q학습이라는 강화학습 알고리즘을 기초로 한다.\n",
    "\n",
    "Q학습에서는 최적 행동 가치 함수로 최적인 행동을 정한다. 이 함수를 딥러닝(CNN)으로 비슷하게 흉내 내어 사용하는 것이 DQN이다.\n",
    "\n",
    "DQN 연구 중에서는 비디오 게임을 자율 학습시켜 사람을 뛰어넘는 수준의 조작을 실현한 사례가 보고되고 있다. DQN에서 사용하는 CNN은 게임 영상 프레임(4개의 연속된 프레임)을 입력하여 최종적으로는 게임을 제어하는 움직임(조이스틱 이동량이나 버튼 조작 여부)에 대하여 각 동작의 가치를 출력한다.\n",
    "\n",
    "<font color = blue> [289페이지 그림 8-27 참고] </font>\n",
    "\n",
    "그동안의 비디오 게임 학습에서는 게임의 상태(캐릭터 위치 등)는 미리 추출하는 것이 보통이다. 그러나 DQN에서는 위 그림과 같이 입력 데이터는 비디오 게임의 영상 뿐이다. 이는 DQN의 주목할 점으로, DQN의 응용 가능성을 현격히 높였다고 볼 수 있다. 게임마다 설정을 바꿀 필요없이 단순히 DQN에 게임 영상을 보여주기만 하면 되기 때문이다. \n",
    "\n",
    "실제 DQN은 구성을 변경하지 않고 팩맨과 아타리 같은 많은 게임을 학습할 수 있으며, 뛰어난 성적을 거두고 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
